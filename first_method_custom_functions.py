#!/usr/bin/env python
# coding: utf-8

# In[1]:


get_ipython().run_cell_magic('writefile', 'custom_tools.py', "\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict \n\ndict_additional_columns = {\n    'color_RED': ['RED'],\n    'color_PINK': ['PINK', 'FUSHIA'],\n    'color_BLUE': ['BLUE'],\n    'color_GREEN': ['GREEN'],\n    'color_WHITE': ['WHITE', 'WHIT'],\n    'color_BLACK': ['BLACK', 'BLK', 'BLCK'],\n    'color_CREAM': ['CREAM'],\n    'color_GOLD': ['GOLD'],\n    'color_SILVER': ['SILVER'],\n    'color_COOPER': ['COOPER'],\n    'color_ASSORTED': ['ASSORTED'],\n    'cat_POSTAGE': ['POSTAGE'],\n    'cat_SAMPLES': ['SAMPLES'],\n    'cat_MANUAL': ['Manual'],\n    'cat_FEES': ['Bank Charges', 'bank charges', 'AMAZON FEE', 'CRUK Commission'],\n    'cat_ADJUSTMENT': ['Adjustment'],\n    'cat_SET': ['SET'],\n#     'cat_FURNITURE': ['DRAWER', 'CABINET', 'DRESSER', 'SEAT', 'SIDEBOARD', 'MIRROR', 'TABLE'],\n    'cat_MATERIAL': ['QUILT', 'FLAG'],\n    'material_WOOD': ['WOOD'],\n    'material_CERAMIC': ['CERAMIC'],\n    'material_GLASS': ['GLASS'],\n    'material_GEM': ['AMETHYST', 'DIAMANTE', 'RUBY', 'AMBER', 'TURQUISE', 'QUARTZ', 'GEMSTONE', 'CRYSTAL', 'JADE'],\n    'material_ENAMEL': ['ENAMEL'],\n    'material_METAL': ['COOPER', 'ZINC', 'BRONZE'],\n    'style_RETRO': ['RETRO'],\n    'style_VINTAGE': ['VINTAGE'],\n    'style_HISTORIC': ['EDWARDIAN', 'FRENCH', 'BAROQUE', 'MOROCCAN', 'ANTIQUE', 'ANT', 'RUSTIC', 'REGENCY'],\n    'style_MODERN': ['MODERN', 'SCANDINAVIAN'],\n    'type_JEWELRY': ['NECKLAGE', 'BEAD', 'RING', 'JEWEL', 'BRACELET'],\n    'type_CHRISTMAS': ['CHRISTMAS'],\n    'type_BAG': ['BAG'],\n    'type_CONTAINER': ['TIN', 'BOX', 'CHEST', 'JAR']\n}\ndict_additional_columns.keys()\n\ncountries = ['Saudi Arabia', 'Czech Republic', 'Nigeria', 'Bermuda', 'West Indies', 'Lebanon', 'European Community',\n           'Korea', 'Thailand', 'Brazil']\n\ndef prepare_train_and_test(train, test):\n    test['is_canceled'] = np.NaN\n    df_all = pd.concat([train, test], sort=False)\n    # I didn't use those in the best result but I left them just in case you were curious what I was testing\n    #df_all = prepare_product_customer_statistics(df_all)\n    #df_all['country_aggregated'] = df_all['country'].apply(lambda x: 'Other' if any([country in x for country in countries]) else x)\n    #df_all['cat_country'] = pd.factorize(df_all['country_aggregated'])[0]\n    new_train_all_rows = df_all[~df_all['is_canceled'].isnull()].copy()\n    new_test_all_rows = df_all[df_all['is_canceled'].isnull()].copy()\n    new_train = prepare_dataframe(new_train_all_rows, train=True)\n    new_test = prepare_dataframe(new_test_all_rows, train=False)\n    return new_train, new_test\n\ndef prepare_product_customer_statistics(df_all):\n    def group_to_dict(group_key, agg_func=np.sum):\n        train = df_all[ ~df_all['is_canceled'].isnull()]\n        dict_ = train.groupby(group_key)['is_canceled'].agg(agg_func).to_dict()\n        if -1 in dict_: \n            del dict_[-1]\n        mean = np.mean( list(dict_.values()) )\n        return defaultdict(lambda: mean, dict_)\n    df_all['cnt_p_product_cancel'] = df_all['stock_code'].map(group_to_dict('stock_code')).astype('float64')\n    #df_all['cnt_p_product_cancel_country'] = df_all['stock_code'].map(group_to_dict(['stock_code', 'country'])).astype('float64')\n    df_all['cnt_p_product_orders'] = df_all['stock_code'].map(group_to_dict('stock_code', agg_func=np.size))\n    df_all['ratio_p_product_orders'] = (df_all['cnt_p_product_cancel']/df_all['cnt_p_product_orders']).round(5)\n    df_all['cnt_customer_cancel'] = df_all['customer_id'].map(group_to_dict('customer_id')).astype('float64')\n    df_all['cnt_customer_orders'] = df_all['customer_id'].map(group_to_dict('customer_id', agg_func=np.size))\n    df_all['ratio_customer_orders'] = (df_all['cnt_customer_cancel']/df_all['cnt_customer_orders']).round(5)\n    return df_all\n    \ndef prepare_dataframe(df, train=False):\n    prepared_df = create_orders_df(df, train)\n    prepared_df = get_invoice_date_parameters(prepared_df)\n    prepared_df = get_additional_bool_column_from_description(prepared_df, df)\n    #prepared_df = one_hot_encoding(prepared_df, 'country')\n    return prepared_df\n\ndef prepare_additional_features(df, rows_df):\n    df_all['cnt_p_product_cancel'] = df_all['stock_code'].map(group_to_dict('stock_code')).astype('float64')\n    #df_all['cnt_p_product_cancel_country'] = df_all['stock_code'].map(group_to_dict(['stock_code', 'country'])).astype('float64')\n    df_all['cnt_p_product_orders'] = df_all['stock_code'].map(group_to_dict('stock_code', agg_func=np.size))\n    df_all['ratio_p_product_orders'] = (df_all['cnt_p_product_cancel']/df_all['cnt_p_product_orders']).round(5)\n    def group_to_dict(group_key, column, agg_func=np.sum):\n        dict_ = df.groupby(group_key)[column].agg(agg_func).to_dict()\n        if -1 in dict_: \n            del dict_[-1]\n        mean = np.mean( list(dict_.values()) )\n        return defaultdict(lambda: mean, dict_)\n    df['different_items'] = df['invoice'].map(group_to_dict('invoice','stock_code', agg_func=np.size))\n    #df['all_quantity'] = df['invoice'].map(group_to_dict('invoice','quantity', agg_func=np.sum))\n    df['price_unit_median'] = df['invoice'].map(group_to_dict('invoice', 'price_unit', agg_func=np.median))\n    df['log_price_full_invoice'] = np.log2(df['invoice'].map(group_to_dict('invoice', 'price_total', agg_func=np.sum)) + 6)\n    df['max_return_product_invoice'] = df['invoice'].map(group_to_dict('invoice', 'cnt_p_product_cancel', agg_func=np.max))\n    df['ratio_p_product_orders'] = df['invoice'].map(group_to_dict('invoice', 'ratio_p_product_orders', agg_func=np.max))\n    return df\n\ndef get_additional_column_from_description(prepared_df, df):\n    columns = list(dict_additional_columns.keys())\n    prepared_df[columns] = prepared_df.apply(lambda row: check_for_string(row.name, df, columns), axis=1)\n    return prepared_df\n\ndef get_additional_bool_column_from_description(prepared_df, df):\n    df['description'] = df['description'].astype(str)\n    prepared_df['joined_descriptions'] = prepared_df.apply(lambda row: ' | '.join(df[df['invoice'] == row.name]['description']), axis=1)\n    for column, words in dict_additional_columns.items():\n        prepared_df[column] = prepared_df['joined_descriptions'].apply(lambda x: any([word in x for word in words]))\n    return prepared_df\n\ndef create_orders_df(df, train=False):\n    columns_count = ['quantity']\n    columns_sum = ['price_total', 'quantity']\n    columns_first = ['invoice_date', 'country_aggregated', 'customer_id', 'is_test']\n    #, 'cnt_customer_cancel', 'cnt_customer_orders', 'ratio_customer_orders']\n    columns_calculations = ['price_unit', 'price_total'] \n    #, 'cnt_p_product_cancel', 'cnt_p_product_orders', 'ratio_p_product_orders']\n    if train:\n        columns_sum.append('is_canceled')\n    orders = df.groupby('invoice')[columns_sum].sum()\n    if train:\n        orders['is_canceled'] = orders['is_canceled'] > 0\n        orders['total_return'] = orders['price_total'] * orders['is_canceled'] \n    orders_temp = df.groupby('invoice')[columns_first].first()\n    orders = orders.join(orders_temp, how='inner')\n    for column in columns_calculations:\n        df[column] = df[column].astype(np.float32)\n        grouped_single = df.groupby('invoice').agg({column: ['mean', 'min', 'max', 'median', 'std']})\n        grouped_single.columns = [f'{column}_{calculation}' for calculation in ['mean', 'min', 'max', 'median', 'std']]\n        grouped_single[f'{column}_std'] = grouped_single[f'{column}_std'].round(2).fillna(-1)\n        if column != 'price_total':\n            grouped_single[f'{column}_min_max_diff'] = grouped_single[f'{column}_max'] - grouped_single[f'{column}_min']\n        orders = orders.join(grouped_single, how='inner')\n    orders_temp = df.groupby('invoice')[columns_count].count()\n    orders_temp = orders_temp.rename(columns={'quantity': 'different_items'})\n    orders = orders.join(orders_temp, how='inner')\n    orders['unknown_buyer'] = np.where(orders['customer_id'] == -1, True, False)\n    orders['log_price_total'] = np.log2(orders['price_total'] + 6)\n    return orders\n    \ndef get_invoice_date_parameters(df):\n    #df['year'] = df['invoice_date'].dt.year\n    df['month'] = df['invoice_date'].dt.month\n    #df['day'] = df['invoice_date'].dt.day\n    df['hour'] = df['invoice_date'].dt.hour\n    #df['minute'] = df['invoice_date'].dt.minute\n    #df['day_of_year'] = df['invoice_date'].dt.dayofyear\n    df['day_of_week'] = df['invoice_date'].dt.dayofweek\n    #df['week_of_year'] = df['invoice_date'].dt.weekofyear\n    #df['quarter'] = df['invoice_date'].dt.quarter\n    df['weekend'] = np.where(df['day_of_week'] < 5, 0, 1)\n    #df['parT_of_day'] = df['hour'].apply(lambda c: get_part_of_day(c))\n    return df\n\ndef get_part_of_day(hour):\n    return (\n        0 if 5 <= hour <= 11\n        else\n        1 if 12 <= hour <= 17\n        else\n        2 if 18 <= hour <= 22\n        else\n        3\n    )\n\ndef one_hot_encoding(df, column):\n    df[column] = pd.Categorical(df[column])\n    df = pd.concat([df, pd.get_dummies(df[column], prefix=column)], axis=1)\n    return df\n\ndef get_features(df, black_list=['total_return', 'is_canceled', 'is_test', 'price_unit_std', 'day_of_week']):\n    feats = df.select_dtypes(include=[np.number, 'bool']).columns\n    return [x for x in feats if x not in black_list]\n\ndef tidy_split(df, column, sep='|', keep=False):\n    indexes = list()\n    new_values = list()\n    df = df.dropna(subset=[column])\n    for i, presplit in enumerate(df[column].astype(str)):\n        values = presplit.split(sep)\n        if keep and len(values) > 1:\n            indexes.append(i)\n            new_values.append(presplit)\n        for value in values:\n            indexes.append(i)\n            new_values.append(value)\n    new_df = df.iloc[indexes, :].copy()\n    new_df[column] = new_values\n    return new_df")


# In[ ]:




